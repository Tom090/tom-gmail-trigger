"use strict";
var __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    var desc = Object.getOwnPropertyDescriptor(m, k);
    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
      desc = { enumerable: true, get: function() { return m[k]; } };
    }
    Object.defineProperty(o, k2, desc);
}) : (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    o[k2] = m[k];
}));
var __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {
    Object.defineProperty(o, "default", { enumerable: true, value: v });
}) : function(o, v) {
    o["default"] = v;
});
var __importStar = (this && this.__importStar) || function (mod) {
    if (mod && mod.__esModule) return mod;
    var result = {};
    if (mod != null) for (var k in mod) if (k !== "default" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);
    __setModuleDefault(result, mod);
    return result;
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.HttpOperationExecution = void 0;
const TE = __importStar(require("fp-ts/TaskEither"));
const E = __importStar(require("fp-ts/Either"));
const O = __importStar(require("fp-ts/Option"));
const function_1 = require("fp-ts/function");
const Array_1 = require("fp-ts/Array");
const uuid_1 = require("uuid");
const querystring = __importStar(require("querystring"));
const OperationHandler_1 = require("@trayio/cdk-dsl/connector/operation/OperationHandler");
const HttpOperationHandler_1 = require("@trayio/cdk-dsl/connector/operation/HttpOperationHandler");
const Http_1 = require("@trayio/commons/http/Http");
const JsonSerialization_1 = require("@trayio/commons/serialization/JsonSerialization");
const BufferExtensions_1 = require("@trayio/commons/buffer/BufferExtensions");
const mime = require('mime');
const { AWS_LAMBDA_FUNCTION_MEMORY_SIZE, CONNECTOR_MAX_ALLOCATED_RAM_MB } = process.env;
class HttpOperationExecution {
    jsonSerialization;
    httpClient;
    handler;
    fileStorage;
    globalConfiguration;
    handlerType;
    constructor(httpClient, fileStorage, handler, globalConfiguration, handlerType) {
        this.jsonSerialization = new JsonSerialization_1.JsonSerialization();
        this.httpClient = httpClient;
        this.fileStorage = fileStorage;
        this.handler = handler;
        this.globalConfiguration = globalConfiguration;
        this.handlerType = handlerType;
    }
    async execute(ctx, input) {
        const request = (0, function_1.pipe)(this.globalConfiguration, O.match(() => this.handler.request, (globalConfig) => this.decorateRequest(globalConfig, this.handler.request, ctx)));
        const operationRequest = this.handler.requestHandler(ctx, input, request);
        const httpRequestE = await this.operationRequestToHttpRequest(operationRequest)();
        if (E.isLeft(httpRequestE)) {
            return OperationHandler_1.OperationHandlerResult.failure(OperationHandler_1.OperationHandlerError.connectorError(httpRequestE.left.message));
        }
        const resultTE = this.httpClient.execute(operationRequest.method, operationRequest.path, httpRequestE.right);
        const operationResponseTE = (0, function_1.pipe)(resultTE, 
        // get the dsl http response object
        TE.map((response) => this.handler.responseHandler(ctx, input, new HttpOperationHandler_1.HttpOperationResponseBuilder(response, this.defaultErrorHandling(response.statusCode), O.none))), 
        // interpret the dsl response object by mapping the low level http response to a connector response
        TE.chain((operationResponse) => this.parseResponse(operationResponse)), 
        // handle errors during the execution of the http request or parsing or the http response
        TE.mapLeft((error) => OperationHandler_1.OperationHandlerResult.failure(OperationHandler_1.OperationHandlerError.connectorError(error.message))));
        return TE.toUnion(operationResponseTE)();
    }
    decorateRequest(globalConfig, operationRequest, ctx) {
        return (0, function_1.pipe)(globalConfig.baseUrl, O.fold(() => operationRequest, (baseUrl) => operationRequest.withUrl(`${baseUrl(ctx)}${operationRequest.path}`)), (request) => (0, function_1.pipe)(globalConfig.bearerToken, O.fold(() => request, (bearerToken) => request.withBearerToken(bearerToken(ctx)))), (request) => (0, function_1.pipe)(globalConfig.headers, (headers) => {
            if (headers.length === 0) {
                return request;
            }
            return headers.reduce((acc, header) => {
                const resolvedHeader = header(ctx);
                return acc.addHeader(resolvedHeader.name, resolvedHeader.value);
            }, request);
        }));
    }
    operationRequestToHttpRequest(operationRequest) {
        return (0, function_1.pipe)(operationRequest.contentType, O.map((contentType) => {
            switch (contentType) {
                case Http_1.HttpContentType.Json:
                    return this.serializeAsJson(operationRequest.body);
                case Http_1.HttpContentType.FormUrlEncoded:
                    return this.serializeAsFormUrlEncoded(operationRequest.body);
                case Http_1.HttpContentType.OctetStream:
                    return this.serializeAsFile(operationRequest);
                case Http_1.HttpContentType.MultipartRequestBody:
                    return this.serializeAsMultipart(operationRequest.body);
                case Http_1.HttpContentType.Text:
                    return this.serializeAsText(operationRequest.body);
                default:
                    return this.serializeAsJson(operationRequest.body);
            }
        }), O.getOrElse(() => this.serializeEmptyBody()), TE.map((serializedBody) => ({
            ...operationRequest.request,
            body: serializedBody,
        })));
    }
    serializeAsJson(body) {
        const serializedBody = this.jsonSerialization.serialize(body);
        return TE.right(BufferExtensions_1.BufferExtensions.arrayBufferToReadable(serializedBody));
    }
    serializeAsFormUrlEncoded(body) {
        const serializedBody = querystring.stringify(body);
        return TE.right(BufferExtensions_1.BufferExtensions.arrayBufferToReadable(new TextEncoder().encode(serializedBody)));
    }
    serializeAsText(body) {
        const serializedBody = new TextEncoder().encode(body);
        return TE.right(BufferExtensions_1.BufferExtensions.arrayBufferToReadable(serializedBody));
    }
    serializeAsMultipart(body) {
        const fileStreamsFromReferencesTasks = Object.keys(body.files).map((fileKey) => {
            const fileRef = body.files[fileKey];
            return (0, function_1.pipe)(this.httpClient.execute(Http_1.HttpMethod.Get, fileRef.url, {
                headers: {},
                pathParams: {},
                queryString: {},
                body: BufferExtensions_1.BufferExtensions.arrayBufferToReadable(new ArrayBuffer(0)),
            }), TE.chain((response) => {
                if (response.statusCode >= 300) {
                    return TE.left(Error('error downloading file from source'));
                }
                const parsedSized = Number.parseInt(response.headers.ContentLength ||
                    response.headers['content-length'], 10);
                return TE.right({
                    key: fileKey,
                    metadata: {
                        name: fileRef.name,
                        size: Number.isNaN(parsedSized) ? undefined : parsedSized,
                        contentType: fileRef.mime_type,
                    },
                    content: response.body,
                });
            }));
        });
        const filesTask = (0, Array_1.sequence)(TE.MonadTask)(fileStreamsFromReferencesTasks);
        return (0, function_1.pipe)(filesTask, TE.map((files) => files.reduce((acc, file) => {
            acc[file.key] = file;
            return acc;
        }, {})), TE.map((multipartFiles) => ({
            fields: body.fields,
            files: multipartFiles,
        })));
    }
    serializeAsFile(operationRequest) {
        const downloadFilefromReference = this.httpClient.execute(Http_1.HttpMethod.Get, operationRequest.body.url, {
            headers: {},
            pathParams: {},
            queryString: {},
            body: BufferExtensions_1.BufferExtensions.arrayBufferToReadable(new ArrayBuffer(0)),
        });
        return (0, function_1.pipe)(downloadFilefromReference, TE.chain((response) => {
            if (response.statusCode >= 300) {
                return TE.left(Error('error downloading file from source'));
            }
            return TE.right(response.body);
        }));
    }
    serializeEmptyBody() {
        return TE.right(BufferExtensions_1.BufferExtensions.arrayBufferToReadable(new ArrayBuffer(0)));
    }
    defaultErrorHandling(statusCode) {
        return () => OperationHandler_1.OperationHandlerResult.failure(OperationHandler_1.OperationHandlerError.apiError(`API returned a status code of ${statusCode}`, {
            statusCode,
        }));
    }
    parseErrorResponse(operationResponse) {
        return (0, function_1.pipe)(operationResponse.contentType, O.fold(() => this.parseEmptyBody(operationResponse), (contentType) => {
            switch (contentType) {
                case Http_1.HttpContentType.Json:
                    const bufferTE = BufferExtensions_1.BufferExtensions.readableToArrayBuffer(operationResponse.response.body);
                    return (0, function_1.pipe)(bufferTE, TE.chain((buffer) => {
                        const deserializedBodyE = this.jsonSerialization.deserialize(buffer);
                        return TE.fromEither(deserializedBodyE);
                    }));
                default:
                    return TE.right(undefined);
            }
        }));
    }
    parseResponse(operationResponse) {
        if (operationResponse.response.statusCode >= 300) {
            return (0, function_1.pipe)(this.parseErrorResponse(operationResponse), TE.chain((result) => TE.right(operationResponse.errorHandling(result))));
        }
        return (0, function_1.pipe)(operationResponse.contentType, O.map((contentType) => {
            switch (contentType) {
                case Http_1.HttpContentType.Json:
                    return this.parseBodyAsJson(operationResponse);
                case Http_1.HttpContentType.OctetStream:
                    return this.parseBodyAsFile(operationResponse);
                case Http_1.HttpContentType.MultipartRequestBody:
                    return TE.right(OperationHandler_1.OperationHandlerResult.failure(OperationHandler_1.OperationHandlerError.connectorError(`Invalid Response Type ${contentType}`)));
                case Http_1.HttpContentType.Text:
                    return this.parseBodyAsText(operationResponse);
                default:
                    return this.parseBodyAsJson(operationResponse);
            }
        }), O.getOrElse(() => this.parseEmptyBody(operationResponse)));
    }
    parseBodyAsJson(operationResponse) {
        const bufferTE = BufferExtensions_1.BufferExtensions.readableToArrayBuffer(operationResponse.response.body);
        return (0, function_1.pipe)(bufferTE, TE.chain((buffer) => {
            const deserializedBodyE = this.jsonSerialization.deserialize(buffer);
            return TE.fromEither(deserializedBodyE);
        }), TE.map((deserializedBody) => operationResponse.responseParser(deserializedBody)));
    }
    parseEmptyBody(operationResponse) {
        return TE.right(operationResponse.responseParser(undefined));
    }
    parseBodyAsFile(operationResponse) {
        const contentType = (operationResponse.response.headers[Http_1.HttpHeader.ContentType.toLowerCase()]);
        const fileExtension = mime.getExtension(contentType);
        const contentLength = (operationResponse.response.headers[Http_1.HttpHeader.ContentLength.toLowerCase()]);
        const uploadOptions = this.generateUploadOptions(contentLength);
        return (0, function_1.pipe)(this.fileStorage.write({
            content: operationResponse.response.body,
            key: fileExtension ? `${(0, uuid_1.v4)()}.${fileExtension}` : (0, uuid_1.v4)(),
            metadata: {
                name: (0, uuid_1.v4)(),
                size: parseFloat(contentLength ?? undefined),
                contentType,
            },
        }, O.some(uploadOptions)), TE.chain((file) => (0, function_1.pipe)(this.fileStorage.getSharedUrl(file.key), TE.map((sharedUrl) => operationResponse.responseParser({
            name: file.metadata.name,
            url: sharedUrl.url,
            mime_type: file.metadata.contentType ?? '',
            expires: sharedUrl.expires ?? 0,
        })))));
    }
    parseBodyAsText(operationResponse) {
        const arrayBufferTE = BufferExtensions_1.BufferExtensions.readableToArrayBuffer(operationResponse.response.body);
        return (0, function_1.pipe)(arrayBufferTE, TE.chain((arrayBuffer) => {
            const deserializeBody = new TextDecoder().decode(arrayBuffer);
            return TE.right(operationResponse.responseParser(deserializeBody));
        }));
    }
    // This method is used to respect lambda memory limits as per the old falfel implementation
    generateUploadOptions(contentLength) {
        const allocatedRam = AWS_LAMBDA_FUNCTION_MEMORY_SIZE || CONNECTOR_MAX_ALLOCATED_RAM_MB;
        const availableRAM = allocatedRam ? parseInt(allocatedRam, 10) : 128; // 128MB default
        const uploadMinSize = 1024 * 1024 * 8, // 8MB
        maxRam = 1024 * 1024 * availableRAM;
        /*
            128 / 16 = 8 (which is UPLOAD_MIN_SIZE)
            TARGET_SIZE should either be 8MB (since default assumed RAM is 128MB) or
            1/16 of of the availableRAM, which ever is greater. The TARGET_SIZE, set
            as `partSize`, will always be used in conjuction with `queueSize`.
        */
        const sixteenthOfRAM = Math.floor(maxRam / 16);
        const targetSize = sixteenthOfRAM < uploadMinSize ? uploadMinSize : sixteenthOfRAM;
        const uploadOptions = {
            // 8MB (minimum) * 4 parallel = upto 32MB/s RAM usage
            partSize: targetSize,
            queueSize: 4,
            acl: 'bucket-owner-full-control',
        };
        if (!contentLength) {
            if (CONNECTOR_MAX_ALLOCATED_RAM_MB) {
                uploadOptions.queueSize = 12;
            }
        }
        else if (parseInt(contentLength, 10) > targetSize &&
            parseInt(contentLength, 10) > targetSize * 8) {
            uploadOptions.queueSize = 12;
        }
        return uploadOptions;
    }
}
exports.HttpOperationExecution = HttpOperationExecution;
